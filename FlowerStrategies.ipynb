{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowerStrategies.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JVcgAAiaihnx",
        "wt3_SmQKnpRO",
        "POBApsmwuCx2"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# Moving Beyond FedAvg with Flower Strategies\n",
        "\n",
        "Welcome to the next practical of the KAICD course on federated learning with Flower. In this notebook, we'll begin to customize the federated learning system we built in the introductory notebook (again, using Flower and PyTorch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Before we begin with any actual code, let's start make sure that we have everything we need. We recommend switching to a runtime with GPU acceleration enabled (on Google Colab: `Runtime > Change runtime type > Hardware acclerator: GPU > Save`). Colab is not always able to offer GPU acceleration. If you see an error related to GPU availability in the next part, consider switching back to CPU-based execution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "Next, we install and import the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTrCL2FmC5U5"
      },
      "source": [
        "!pip install torch==1.9.0 torchvision==0.10.0 git+https://github.com/adap/flower.git@release/0.17#egg=flwr[\"simulation\"]\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "DEVICE = \"cpu\"  # Enable this line to force execution on CPU\n",
        "print(f\"Training on {DEVICE}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2bnPKG58Gx"
      },
      "source": [
        "If you run on Google Colab and your runtime has a GPU accelerator, you should see the output `Training on cuda:0`, otherwise it'll say `Training on cpu`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "### Data loading\n",
        "\n",
        "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap everything in their own `DataLoader`. We introduce a new parameter `num_clients` which allows us to call `load_datasets` with different numbers of clients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4Em7BPNTXeX"
      },
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "def load_datasets(num_clients: int):\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // num_clients\n",
        "    lengths = [partition_size] * num_clients\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBp7kB4G0sPB"
      },
      "source": [
        "### Model training/evaluation\n",
        "\n",
        "Let's continue with the usual model definition, training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(testloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lCf3oljdClM"
      },
      "source": [
        "### Flower client\n",
        "\n",
        "To implement the Flower client, we (again) create a subclass of `flwr.client.NumPyClient` and implement the three methods `get_parameters`, `fit`, and `evaluate`. Here, we also pass the `cid` to the client and use it log additional details:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye6Jt5p3LWtF"
      },
      "source": [
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, net, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=1)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    net = Net().to(DEVICE)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, net, trainloader, valloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6HP2cYCsqxD"
      },
      "source": [
        "## Strategy customization\n",
        "\n",
        "So far, everything should look somewhat familiar from the introductory notebook. Now, on to the shiny new features! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6FHRf8HrbzV"
      },
      "source": [
        "### Server-side parameter **initialization**\n",
        "\n",
        "Flower, by default, initializes the global model by asking one random client for the initial parameters. In many cases, we want more control over parameter initialization though. Flower therefore allows you to directly pass the initial parameters to the Strategy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPeFWwyFrY9f"
      },
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "net = Net()\n",
        "params = get_parameters(Net())\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(params),\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4q2B84tMduY"
      },
      "source": [
        "Passing `initial_parameters` to the `FedAvg` strategy prevents Flower from asking one of the clients for the initial parameters. If we look closely, we can see that the logs do not show any calls to the `FlowerClient.get_parameters` method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axzXSMtlfhXU"
      },
      "source": [
        "### Starting with a customized strategy\n",
        "\n",
        "We've seen the function `start_simulation` before. It accepts a number of arguments, amongst them the `client_fn` used to create `FlowerClient` instances, the number of clients to simulate `num_clients`, the number of rounds `num_rounds`, and the strategy.\n",
        "\n",
        "The strategy encapsulates the federated learning approach/algorithm, for example, `FedAvg` or `FedAdam`. Let's try to use a different strategy this time:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELNy0-0nfyI2"
      },
      "source": [
        "# Create FedAdam strategy\n",
        "strategy=fl.server.strategy.FedYogi(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNe-UmmOrCuW"
      },
      "source": [
        "Here are two ideas we could try out:\n",
        "- How could we change the strategy back to FedAvg?\n",
        "- Do you get a different result after five rounds of training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt3_SmQKnpRO"
      },
      "source": [
        "## Server-side parameter **evaluation**\n",
        "\n",
        "Flower can evaluate the aggregated model on the server-side or on the client-side. Client-side and server-side evaluation are similar in some ways, but different in others.\n",
        "\n",
        "**Centralized Evaluation** is conceptually simple: it works the same way that evaluation in centralized machine learning does. If there is a server-side dataset that can be used for evaluation purposes, then that's great. We can evaluate the newly aggregated model after each round of training without having to send the model to clients. We're also fortunate in the sense that our entire evaluation dataset is available at all times.\n",
        "\n",
        "**Federated Evaluation** is more complex, but also more powerful: it doesn't require a centralized dataset and allows us to evaluate models over a larger set of data, which often yields more realistic evaluation results. In fact, many scenarios require us to use **Federated Evaluation** if we want to get representative evaluation results at all. But this power comes at a cost: once we start to evaluate on the client side, we must be aware that our evaluation dataset can change over consecutive rounds of learning if those clients are not always available. The evaluation results are not stable, so even if we do not change the model, we'd see our evaluation results fluctuate over consecutive rounds because clients are not always available (and because the dataset on each client can change).\n",
        "\n",
        "We've seen how federated evaluation works on the client side (i.e., by implementing the `evaluate` method in `FlowerClient`). Now let's see how we can evaluate on the server-side:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDovnUvsn7if"
      },
      "source": [
        "# Create a function that returns an evaluation function\n",
        "def get_evaluation_fn():\n",
        "\n",
        "    # Load data and model here to avoid the overhead of doing it in the\n",
        "    # following `evaluate` function itself\n",
        "    net = Net()\n",
        "    valloader = valloaders[0]\n",
        "\n",
        "    # The `evaluate` function will be by Flower called after every round\n",
        "    def evaluate(\n",
        "        weights: fl.common.Weights,\n",
        "    ) -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "        set_parameters(net, weights)  # Update model with the latest parameters\n",
        "        loss, accuracy = test(net, valloader)\n",
        "        print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5aGRnyQnu0Z"
      },
      "source": [
        "# # Pass the evaluation function to the Strategy\n",
        "# strategy=fl.server.strategy.FedAdam(\n",
        "#     fraction_fit=1.0,\n",
        "#     fraction_eval=1.0,\n",
        "#     min_fit_clients=10,\n",
        "#     min_eval_clients=10,\n",
        "#     min_available_clients=10,\n",
        "#     initial_parameters=fl.common.weights_to_parameters(\n",
        "#         get_parameters(Net())\n",
        "#     ),\n",
        "#     eval_fn=get_evaluation_fn(),\n",
        "# )\n",
        "\n",
        "# # Start simulation\n",
        "# fl.simulation.start_simulation(\n",
        "#     client_fn=client_fn,\n",
        "#     num_clients=NUM_CLIENTS,\n",
        "#     num_rounds=3,\n",
        "#     strategy=strategy,\n",
        "# )\n",
        "\n",
        "\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.3,\n",
        "    fraction_eval=0.3,\n",
        "    min_fit_clients=3,\n",
        "    min_eval_clients=3,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.weights_to_parameters(get_parameters(Net())),\n",
        "    eval_fn=get_evaluation_fn(),  # Pass the evaluation function\n",
        ")\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    num_rounds=3,  # Just three rounds\n",
        "    strategy=strategy,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0NhITbH4Kmd"
      },
      "source": [
        "## Exchanging arbitrary values\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yW_cnCapDN9"
      },
      "source": [
        "### Sending arbitrary values from server to client\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPNBmtcm4aWN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KumHVIfHpI5o"
      },
      "source": [
        "### Returning arbitrary values from client to server\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUMIuer-pNKe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POBApsmwuCx2"
      },
      "source": [
        "## Scaling federated learning\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVTrw7OsttE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez00lLOA3waL"
      },
      "source": [
        "## Recap\n",
        "\n",
        "In this notebook, we've seen how we can gradually enhance our system by customizing the strategy, initializing parameters on the server side, choosing a different strategy, evaluating models on the server-side.\n",
        "\n",
        "Quite a bit of power for so little code!\n",
        "\n",
        "\n",
        "\n",
        "In the last sections, we've seen how we can communicate arbitrary values between server and clients to fully customize client-side execution. With that capability, we built a large-scale Federated Learning simulation using the Flower Virtual Client Engine and ran an experiment involving 1000 clients in the same workload - all in a Jupyter Notebook!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqWklwDJqBqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}