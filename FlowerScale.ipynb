{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowerScale.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JVcgAAiaihnx",
        "wt3_SmQKnpRO",
        "POBApsmwuCx2"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz71fPGrpRiQ"
      },
      "source": [
        "# Large-Scale Federated Learning with Flower\n",
        "\n",
        "Welcome to the KAICD course on federated learning with Flower, part 2!\n",
        "\n",
        "In this notebook, we'll customize the federated learning system we built in part 1 (again, using Flower and PyTorch). In part 1, we use PyTorch for the model training pipeline and data loading. In part 2, we continue to federate the PyTorch-based pipeline using Flower."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBu1HRRY6bwX"
      },
      "source": [
        "## Part 0: Preparation\n",
        "\n",
        "Before we begin with any actual code, let's start make sure that we have everything we need. We recommend switching to a runtime with GPU acceleration enabled (on Google Colab: `Runtime > Change runtime type > Hardware acclerator: GPU > Save`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4KiTMTpiort"
      },
      "source": [
        "### Installing dependencies\n",
        "\n",
        "Next, we install and import the necessary packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTrCL2FmC5U5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb5111c-7ef9-49fa-dd24-ca0188a9aa16"
      },
      "source": [
        "!pip install torch==1.9.0 torchvision==0.10.0 git+https://github.com/adap/flower.git@release/0.17#egg=flwr[\"simulation\"]\n",
        "\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import flwr as fl\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Training on {DEVICE}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flwr[simulation]\n",
            "  Cloning https://github.com/adap/flower.git (to revision release/0.17) to /tmp/pip-install-o5dfdrvu/flwr_bc542f8c16e74044acdbc2f792938cf6\n",
            "  Running command git clone -q https://github.com/adap/flower.git /tmp/pip-install-o5dfdrvu/flwr_bc542f8c16e74044acdbc2f792938cf6\n",
            "  Running command git checkout -b release/0.17 --track origin/release/0.17\n",
            "  Switched to a new branch 'release/0.17'\n",
            "  Branch 'release/0.17' set up to track remote branch 'release/0.17' from 'origin'.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision==0.10.0 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu111)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (1.41.0)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (2.0.3)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (1.19.5)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (3.17.3)\n",
            "Requirement already satisfied: ray[default]==1.6.0 in /usr/local/lib/python3.7/dist-packages (from flwr[simulation]) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (3.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (3.3.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (1.0.2)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (3.5.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (21.2.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (0.8.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (2.6.0)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (0.3.10)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (0.11.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (3.7.4.post0)\n",
            "Requirement already satisfied: aioredis<2 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (2.23.0)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (0.6.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (0.5.4)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.6.0->flwr[simulation]) (0.7.0)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis<2->ray[default]==1.6.0->flwr[simulation]) (2.0.0)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.7/dist-packages (from aioredis<2->ray[default]==1.6.0->flwr[simulation]) (3.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr[simulation]) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr[simulation]) (1.15.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]==1.6.0->flwr[simulation]) (1.7.0)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]==1.6.0->flwr[simulation]) (3.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray[default]==1.6.0->flwr[simulation]) (5.2.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->ray[default]==1.6.0->flwr[simulation]) (2.10)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[default]==1.6.0->flwr[simulation]) (5.4.8)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[default]==1.6.0->flwr[simulation]) (1.7)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray[default]==1.6.0->flwr[simulation]) (7.352.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.6.0->flwr[simulation]) (1.26.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.6.0->flwr[simulation]) (0.1.2)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (21.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (2018.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (0.2.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (2.4.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.21.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.6.0->flwr[simulation]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.6.0->flwr[simulation]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.6.0->flwr[simulation]) (2021.5.30)\n",
            "Training on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D2bnPKG58Gx"
      },
      "source": [
        "If you run on Google Colab and your runtime has a GPU accelerator, you should see the output `Training on cuda:0`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVcgAAiaihnx"
      },
      "source": [
        "### Data loading\n",
        "\n",
        "Let's now load the CIFAR-10 training and test set, partition them into ten smaller datasets (each split into training and validation set), and wrap everything in their own `DataLoader`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4Em7BPNTXeX",
        "outputId": "7ac49c50-e3a6-4704-e5e4-fc63ece6a975"
      },
      "source": [
        "NUM_CLIENTS = 10\n",
        "\n",
        "def load_datasets():\n",
        "    # Download and transform CIFAR-10 (train and test)\n",
        "    transform = transforms.Compose(\n",
        "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    )\n",
        "    trainset = CIFAR10(\"./dataset\", train=True, download=True, transform=transform)\n",
        "    testset = CIFAR10(\"./dataset\", train=False, download=True, transform=transform)\n",
        "\n",
        "    # Split training set into 10 partitions to simulate the individual dataset\n",
        "    partition_size = len(trainset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    datasets = random_split(trainset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in datasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=32))\n",
        "    testloader = DataLoader(testset, batch_size=32)\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBp7kB4G0sPB"
      },
      "source": [
        "### Model training/evaluation\n",
        "\n",
        "Let's continue with the usual model definition, training and test functions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2X3cVBXMpP6w"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(testloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0NhITbH4Kmd"
      },
      "source": [
        "## Sending arbitrary values server to client\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPNBmtcm4aWN"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWri0Ys25cAt"
      },
      "source": [
        "## Sending arbitrary values from client to server\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1lw17Kk5gbu"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POBApsmwuCx2"
      },
      "source": [
        "## Customizing the Strategy implementation\n",
        "\n",
        "TODO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVTrw7OsttE7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez00lLOA3waL"
      },
      "source": [
        "## Recap\n",
        "\n",
        "In this notebook, we've seen how we can communicate arbitrary values between server and clients to fully customize client-side execution. With that capability, we built a large-scale Federated Learning simulation using the Flower Virtual Client Engine and ran an experiment involving 1000 clients in the same workload - all in a Jupyter Notebook!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNIttlvv6e14"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}